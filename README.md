# Re<span style="color:red">fair</span>mulate: A Benchmark Dataset for Gender-Fair Query Reformulations

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![arXiv](https://img.shields.io/badge/arXiv-2025.XXXX-b31b1b.svg)]()

**Refairmulate** is the first large-scale benchmark dataset specifically designed for fairness-aware query reformulation in Information Retrieval (IR) systems. The dataset contains over **300,000 query pairs** that enable dual-objective optimization of both retrieval effectiveness and gender bias mitigation.

## ğŸŒŸ Key Features

- ğŸ¯ **Multi-objective optimization** for both effectiveness and fairness
- ğŸ“Š **300,000+ query pairs** derived from MS MARCO passage retrieval corpus
- ğŸ” **Three specialized subsets**: Optimal, Effective, and Fair
- âš–ï¸ **Comprehensive bias metrics**: ARaB variants and LIWC
- ğŸš€ **Cross-model validation** across SPLADE, SBERT, TCT-ColBERT, and ANCE
- ğŸ“ˆ **Demonstrated improvements**: Up to 76.0% MRR@10 gains and 94.5% bias reduction

## ğŸ“‹ Table of Contents

- [Dataset Overview](#-dataset-overview)
- [Dataset Structure](#-dataset-structure)
- [Methodology](#-methodology)
- [Installation](#-installation)
- [Usage Examples](#-usage-examples)
- [Benchmarking Results](#-benchmarking-results)
- [Citation](#-citation)
- [License](#-license)

## ğŸ“Š Dataset Overview

The Refairmulate dataset addresses a critical gap in fairness-aware query reformulation by providing systematically constructed query pairs that optimize for both retrieval effectiveness and gender bias reduction.

### Dataset Statistics

| Subset | Query Pairs | MRR@10 Improvement | Bias Reduction | Use Case |
|--------|-------------|-------------------|----------------|----------|
| **Optimal** | 112,261 | +855.7% | -100.0% | Theoretical upper bound |
| **Effective** | 209,343 | +426.9% | -388.5% | Performance-focused improvements |
| **Fair** | 321,604 | +476.2% | -506.2% | Comprehensive fairness training |

### Key Metrics

- **Effectiveness Metrics**: Mean Reciprocal Rank (MRR@10), Average Precision (AP@10)
- **Bias Metrics**: ARaB-tc, ARaB-tf, ARaB-bool, LIWC
- **Multi-objective Scoring**: S(q, q') = w_e Ã— Î”eff(q, q') + w_b Ã— Î”bias(q, q')

## ğŸ—ï¸ Dataset Structure

The Refairmulate dataset is partitioned into three subsets, each targeting distinct fairness-effectiveness trade-offs:

### ğŸ“ˆ Optimal Subset
- **Size**: 112,261 query pairs
- **Objective**: Perfect dual optimization (MRR@10 = 1, bias = 0)
- **Use case**: Theoretical upper bound for fairness-performance trade-offs

### âš¡ Effective Subset  
- **Size**: 209,343 query pairs
- **Objective**: Maximal performance improvement under fairness constraints
- **Use case**: Targeted improvements for specific query categories

### âš–ï¸ Fair Subset
- **Size**: 321,604 query pairs
- **Objective**: Measurable bias reduction with flexible performance requirements
- **Use case**: Comprehensive fairness-aware training and evaluation

### Query Group Classification

We categorize queries into 4 groups based on their effectiveness (eff(q, D_q)) and bias (bias(q, D_q)) relative to thresholds (Î¸_eff and Î¸_bias):

- **Group 1**: High Effectiveness, Low Bias - Minimal reformulation needed
- **Group 2**: High Effectiveness, High Bias - Focus on bias reduction while preserving effectiveness
- **Group 3**: Low Effectiveness, Low Bias - Focus on effectiveness improvement
- **Group 4**: Low Effectiveness, High Bias - Comprehensive reformulation for both issues

## ğŸ”¬ Methodology

### Algorithm

The following pseudocode outlines the Refairmulate process for fair and effective query reformulation:

```plaintext
Algorithm: Refairmulate - Fair and Effective Query Reformulation

Input: Query set Q, relevant documents D_q for each q in Q
Output: Reformulated query pairs QP = {(q, q') | q in Q, q' in Q'}

1. Initialize QP as an empty set
2. For each query q in Q:
    a. If C(q) â‰  0, skip q  // Skip biased queries
    b. Compute bias(q, D_q) and eff(q, D_q), then categorize q
    c. Generate variants V_q = G(q, D_q)
    d. For each variant v_q^(i) in V_q:
        i. Compute bias(v_q^(i), D_v_q^(i)) and eff(v_q^(i), D_v_q^(i))
        ii. Calculate score S(q, v_q^(i)) = w_e * Î”eff + w_b * Î”bias
    e. Select q' = argmax_{v_q^(i) in V_q} S(q, v_q^(i))
    f. Add (q, q') to QP
3. Return QP
```

Our construction pipeline follows a three-stage approach: **Classify â†’ Generate â†’ Select**

### 1. Query Classification
- BERT-based filtering for gender-neutral queries
- Removes queries with inherent gender bias
- Ensures bias measurements reflect system behavior

### 2. Query Generation
- LLM-based reformulation with diverse candidates
- Uses transformer models fine-tuned on query-document pairs
- Generates multiple variations per original query

### 3. Multi-objective Selection
- Optimization balancing effectiveness and fairness
- Group-specific selection criteria
- Comprehensive evaluation using multiple bias metrics

```python
# Multi-objective scoring function
S(q, q') = w_e Ã— Î”eff(q, q') + w_b Ã— Î”bias(q, q')

where:
- Î”eff: Effectiveness improvement
- Î”bias: Bias reduction  
- w_e, w_b: Configurable weights
```

## ğŸ’» Installation

### Prerequisites
- Dependencies listed in `requirements.txt`

## ğŸ“ˆ Benchmarking Results

### The overview of our proposed Refairmulate datasets

| Dataset | MRR@10 Source | MRR@10 Destination | MRR@10 Improv. (%) | ARaB-tf@10 Source | ARaB-tf@10 Destination | ARaB-tf@10 Improv. (%) | ARaB-tc@10 Source | ARaB-tc@10 Destination | ARaB-tc@10 Improv. (%) | ARaB-bool@10 Source | ARaB-bool@10 Destination | ARaB-bool@10 Improv. (%) | LIWC@10 Source | LIWC@10 Destination | LIWC@10 Improv. (%) |
|---------|---------------|--------------------|--------------------|-------------------|------------------------|------------------------|-------------------|------------------------|------------------------|---------------------|--------------------------|--------------------------|----------------|---------------------|---------------------|
| **Optimal** | 0.161 | 1.000 | 855.715 | 0.0627 | 0.000 | 100.000 | 0.033 | 0.000 | 100.000 | 0.0348 | 0.000 | 100.000 | 0.132 | 0.000 | 100.000 |
| **Effective** | 0.081 | 0.425 | 426.866 | 0.139 | 0.029 | 388.453 | 0.071 | 0.015 | 370.731 | 0.070 | 0.0156 | 350.393 | 0.273 | 0.081 | 235.330 |
| **Fair** | 0.109 | 0.626 | 476.180 | 0.113 | 0.019 | 506.243 | 0.058 | 0.009 | 488.916 | 0.058 | 0.058 | 469.897 | 0.224 | 0.053 | 322.279 |


### Cross-Model Performance

| Model | MRR@10 Improvement | ARaB Reduction |
|-------|-------------------|----------------|
| SPLADE | +76.0% | -94.5% |
| SBERT | +68.2% | -89.1% |
| TCT-ColBERT | +71.5% | -91.8% |
| ANCE | +65.9% | -87.3% |

### Generalization Performance

| Query Set | Effectiveness | Bias Reduction | Positive Rate |
|-----------|--------------|----------------|---------------|
| 215 queries | +154.6% | -441.3% | 79.07% |
| 1,765 queries | +88.7% | -172.6% | 75.58% |

## ğŸ› ï¸ Repository Structure

```
refairmulate/
â”œâ”€â”€ datasets/                       # Dataset files and evaluation data
â”‚   â”œâ”€â”€ data/                       # Main dataset files
â”‚   â”œâ”€â”€ eval/                       # Evaluation datasets
â”‚   â””â”€â”€ queries/                    # Query collections
â”œâ”€â”€ resources/                      # Pre-computed resources and models
â”‚   â”œâ”€â”€ outputcollection_neutralityscores.tsv
â”‚   â”œâ”€â”€ liwccollection_bias.pkl
â”‚   â”œâ”€â”€ msmarco_passage_docs_bias_tf.pkl
â”‚   â”œâ”€â”€ msmarco_passage_docs_bias_bool.pkl
â”‚   â””â”€â”€ msmarco_passage_docs_bias_tc.pkl
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ classification/             # Query classification pipeline
â”‚   â”‚   â”œâ”€â”€ data/                   # Classification data
â”‚   â”‚   â”œâ”€â”€ model/                  # Classification models
â”‚   â”‚   â”œâ”€â”€ src/                    # Classification source code
â”‚   â”‚   â”œâ”€â”€ scripts/                # Classification scripts
â”‚   â”‚   â”œâ”€â”€ data_loader/            # Data loading utilities
â”‚   â”‚   â””â”€â”€ requirements.txt        # Classification dependencies
â”‚   â”œâ”€â”€ generation/                 # Query generation pipeline
â”‚   â”‚   â”œâ”€â”€ generate.py             # Main generation script
â”‚   â”‚   â””â”€â”€ README.md               # Generation documentation
â”‚   â”œâ”€â”€ selection/                  # Multi-objective selection
â”‚   â”‚   â”œâ”€â”€ src/                    # Selection source code
â”‚   â”‚   â”œâ”€â”€ scripts/                # Selection scripts
â”‚   â”‚   â””â”€â”€ README.md               # Selection documentation
â”‚   â””â”€â”€ benchmark/                  # Benchmarking and evaluation
â”‚       â””â”€â”€ cross-encoder/          # Cross-encoder models
â”œâ”€â”€ .gitattributes                  # Git attributes
â””â”€â”€ README.md                       # This file
```

## ğŸ¯ Use Cases

### Research Applications
- **Ablation studies**: Analyze fairness-performance trade-offs
- **Bias measurement**: Benchmark existing systems for gender bias
- **Model comparison**: Evaluate different retrieval architectures

### Practical Applications
- **Search engine optimization**: Improve both relevance and fairness
- **Content recommendation**: Reduce algorithmic bias in recommendations
- **Academic research**: Support reproducible fairness studies
- **Industry applications**: Deploy fairer IR systems


## ğŸ“– Citation

If you use Refairmulate in your research, please cite our paper:

```bibtex
@article{le2025refairmulate,
  title={Refairmulate: A Benchmark Dataset for Gender-Fair Query Reformulations},
  author={Hai Son, Le and Seyedsalehi, Shirin and Kermani, Morteza Zihayat and Bagheri, Ebrahim},
  journal={TBD},
  year={2025}
}
```

## ğŸ“§ Contact

- **Hai Son Le** - Toronto Metropolitan University
- **Shirin Seyedsalehi** - Toronto Metropolitan University  
- **Morteza Zihayat Kermani** - Toronto Metropolitan University
- **Ebrahim Bagheri** - University of Toronto

For questions and support, please open an issue on GitHub or contact the authors.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built on the MS MARCO passage retrieval corpus
- Evaluation conducted using Anserini toolkit
- Special thanks to the fairness-aware IR research community

## ğŸ”— Related Work

- [MS MARCO Dataset](https://microsoft.github.io/msmarco/)
- [Anserini Toolkit](https://github.com/castorini/anserini)
- [Pyserini Toolkit](https://github.com/castorini/pyserini)
- [SPLADE](https://github.com/naver/splade)
- [Sentence-BERT](https://github.com/UKPLab/sentence-transformers)

---
